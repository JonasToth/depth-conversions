namespace tf {

/** @page chapter2 C2: %Executor

After you create a task dependency graph, you need to submit it to threads for execution.
In this chapter, we will show you how to execute a task dependency graph.

@section C2_CreateAnExecutor Create an Executor

To execute a taskflkow, you need to create an @em executor from tf::Executor.
An executor is a @em thread-safe object that 
manages a set of worker threads and executes tasks
through an efficient @em work-stealing algorithm.
Issuing a call to run a taskflow creates a @em topology,
a data structure to keep track of the execution status of a running graph.
tf::Executor takes an unsigned integer to construct with @c N worker threads.
The default value is std::thread::hardware_concurrency.

@code{.cpp}
tf::Executor executor1;     // create an executor of std::thread::hardware_concurrency worker threads
tf::Executor executor2(4);  // create an executor of 4 worker threads
@endcode

An executor can be reused to execute multiple taskflows.
In most workloads, you may need only one executor to run multiple taskflows
where each taskflow represents a part of a parallel decomposition.

@section C2_ExecuteATaskflow Execute a Taskflow

tf::Executor provides a set of @c run\_* methods,
tf::Executor::run, 
tf::Executor::run_n, and tf::Executor::run_until to run a taskflow
for one time, multiple times, or until a given predicate evaluates to true.
All methods accept an optional callback to invoke after the execution completes,
and return a std::future for users to access the execution status.
The code below shows several ways to run a taskflow.

@code{.cpp}
 1: // Declare an executor and a taskflow
 2: tf::Executor executor;
 3: tf::Taskflow taskflow;
 4:
 5: // Add three tasks into the taskflow
 6: tf::Task A = taskflow.emplace([] () { std::cout << "This is TaskA\n"; });
 7: tf::Task B = taskflow.emplace([] () { std::cout << "This is TaskB\n"; });
 8: tf::Task C = taskflow.emplace([] () { std::cout << "This is TaskC\n"; });
 9: 
10: // Build precedence between tasks
11: A.precede(B, C); 
12: 
13: std::future<void> fu = executor.run(taskflow);
14: fu.wait();                // block until the execution completes
15:
16: executor.run(taskflow, [](){ std::cout << "end of one execution\n"; }).wait();
17: executor.run_n(taskflow, 4);
18: executor.wait_for_all();  // block until all associated executions finish
19: executor.run_n(taskflow, 4, [](){ std::cout << "end of four executions\n"; }).wait();
20: executor.run_until(taskflow, [int cnt=0] () mutable { return (++cnt == 10); });
@endcode


Debrief:

@li Line 6-8   creates a taskflow of three tasks A, B, and C
@li Line 13-14 runs the taskflow once and use std::future::wait to wait for completion 
@li Line 16    runs the taskflow once with a callback to invoke when the execution finishes
@li Line 17-18 runs the taskflow four times and use tf::Executor::wait_for_all to wait for completion 
@li Line 19    runs the taskflow four times and invokes a callback at the end of the forth execution
@li Line 20    keeps running the taskflow until the predicate returns true

Issuing multiple runs on the same taskflow will automatically @em synchronize
to a sequential chain of executions in the order of run calls.

@code{.cpp}
executor.run(taskflow);         // execution 1
executor.run_n(taskflow, 10);   // execution 2
executor.run(taskflow);         // execution 3
executor.wait_for_all();        // execution 1 -> execution 2 -> execution 3
@endcode

A key point to notice is a running taskflow must remain alive during its execution.
It is your responsibility to ensure a taskflow not being destructed
when it is running.
For example, the code below can result undefined behavior.

@code{.cpp}
tf::Executor executor;  // create an executor

// create a taskflow whose lifetime is restricted by the scope
{
  tf::Taskflow taskflow;
  
  // add tasks to the taskflow
  // ... 

  // run the taskflow
  executor.run(f);

} // at this point, taskflow might get destructed while it is running, resulting in defined behavior
@endcode

Similarly, you should avoid touching a taskflow while it is running.

@code{.cpp}
tf::Taskflow taskflow;

// Add tasks into the taskflow
// ...

// Declare an executor
tf::Executor executor;

std::future<void> future = taskflow.run(f);  // non-blocking return

// alter the taskflow while running leads to undefined behavior 
f.emplace([](){ std::cout << "Add a new task\n"; });
@endcode

A rule of thumb is to always keep a taskflow alive in your function scope 
while it is participating in an execution.


@section C2_ThreadSafety Thread Safety

tf::Executor is @em thread-safe. 
Touching an executor from multiple threads is acceptable.
You can have multiple threads call the same executor to run different taskflows.

@code{.cpp}
 1: tf::Executor executor;
 2:
 3: for(int i=0; i<10; ++i) {
 4:   std::thread([i, &](){
 5:     // ... modify my taskflow
 6:     executor.run(taskflows[i]);  // run my taskflow
 7:   }).detach();
 8: }
@endcode

@section C2_MonitorThreadActivities Monitor Thread Activities 

Inspecting the thread activities is very important for performance analysis. 
It allows you to know when each task starts and ends participating in the task scheduling.
Cpp-Taskflow provides a default observer class tf::ExecutorObserver for this purpose.
The following example shows how to create an observer from an executor.

@code{.cpp}
tf::Executor executor;
tf::ExecutorObserver* observer = executor.make_observer<tf::ExecutorObserver>();
@endcode 

Note that each executor can only have an observer at a time. 
An observer will automatically record the start and end timestamps 
of each executed task. Users can query, dump or remove the timestamps through the tf::ExecutorObserver::num_tasks, tf::ExecutorObserver::dump and tf::ExecutorObserver::clear methods. 

@code{.cpp}
 1: tf::Executor executor;
 2: tf::ExecutorObserver* observer = executor.make_observer<tf::ExecutorObserver>();
 3:
 4: executor.run(taskflow).get();  // do something
 5:
 6: // Query the total number of tasks (number of timestamp pairs)
 7: auto num_tasks = observer->num_tasks();
 8:
 9: // Dump the timeline data in JSON format 
10: std::string timelines_in_json = observer->dump();
11: 
12: // Clear the timeline data
13: observer->clear();
@endcode 

Debrief:

@li Line 2-4 creates an observer and a task dependency graph with four tasks and submits the tasks to execution.
@li Line 7 query the total number of tasks (number of timestamp pair) through observer
@li Line 10 dump the timestamps to a std::string in JSON format 
@li Line 13 remove all timestamps in the observer

You can visualize the timeline data in a Chrome browser:

@li Step 1: save the JSON timeline data to a file
@li Step 2: launch the Chrome browser and open a tab with the url: chrome://tracing
@li Step 3: load the JSON file

@image html images/timeline.png width=80%

Tasks will be categorized by the executing thread and each task is named with @em i_j where @em i is the thread id and 
@em j is the task number. 
You can pan or zoom in/out the timeline to get a detailed view.

@section C2_CustomizeYourOwnObserver Customize Your Own Observer 

You can derive your own observer from the base interface class tf::ExecutorObserverInterface 
to customize the observing methods. 


*/

}

